{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23a8c1b8",
   "metadata": {},
   "source": [
    "# OpenVINO Model Server in OpenShift demo\n",
    "\n",
    "This notebook demonstrate how to deploy and use OpenVINO Model Server.\n",
    "That will include the use case with BERT model and a pipeline performing face detection operation and also age, gender and emotion recognition for each detected face.\n",
    "\n",
    "Requirements:\n",
    "- OpenShift cluster with the API access to a project\n",
    "- installed OpenVINO Model Server Operator\n",
    "- Jupyter session with python3 deployed in the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e208a7e6",
   "metadata": {},
   "source": [
    "## Creating Minio storage\n",
    "\n",
    "OpenVINO Model Server can expose over gRPC and REST interface the models stored in the local or cloud storage like AWS S3, google storage or Azure blobs. In OpenShift and Kubernetes every Persistent Storage Claim could be used as well. In this demo will be employed Minio service which is an equivalent of AWS S3.\n",
    "\n",
    "First login to OpenShift cluster API using `oc` tool. In the commands below change the cluster DNS name and the user token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6acdb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s https://downloads-openshift-console.apps.<cluster DNS name>/amd64/linux/oc.tar | tar x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865e852f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged into \"https://api.openvino5.3q12.p1.openshiftapps.com:6443\" as \"dtrawins\" using the token provided.\n",
      "\n",
      "You have access to 100 projects, the list has been suppressed. You can list all projects with 'oc projects'\n",
      "\n",
      "Using project \"default\".\n"
     ]
    }
   ],
   "source": [
    "!oc login --token=<user token> --server=https://api.<cluster DNS name>:6443"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d7baf0",
   "metadata": {},
   "source": [
    "Change the project context where you would like to deploy your services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eefafcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now using project \"ovms\" on server \"https://api.openvino5.3q12.p1.openshiftapps.com:6443\".\n"
     ]
    }
   ],
   "source": [
    "!oc project ovms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52401853",
   "metadata": {},
   "source": [
    "Now deploy Minio service. Note that the configuration below creates Minio server with emphemeral storage which will be deleted each time the pod is restarted. It includes also the default credentials. All in all, it is only a demonstrative purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec46349a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deployment.apps/minio created\n",
      "service/minio-service created\n"
     ]
    }
   ],
   "source": [
    "!oc apply -f https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/ovms-demo/notebooks/202-model-server/minio.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad2cc78",
   "metadata": {},
   "source": [
    "Next step is to connect to the Minio service and create models repository for the OpenVINO Model Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df88cf80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-21 15:01:26--  https://dl.min.io/client/mc/release/linux-amd64/mc\n",
      "Resolving dl.min.io (dl.min.io)... 178.128.69.202\n",
      "Connecting to dl.min.io (dl.min.io)|178.128.69.202|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20426752 (19M) [application/octet-stream]\n",
      "Saving to: ‘mc’\n",
      "\n",
      "mc                  100%[===================>]  19.48M  15.0MB/s    in 1.3s    \n",
      "\n",
      "2021-04-21 15:01:28 (15.0 MB/s) - ‘mc’ saved [20426752/20426752]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.min.io/client/mc/release/linux-amd64/mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "259471e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod 755 mc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb95b5d8",
   "metadata": {},
   "source": [
    "In the command below make sure you have the correct project name. Replace `ovms` with your project name, where minio got deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "022a8d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32mAdded `minio` successfully.\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!./mc alias set minio http://minio-service.ovms:9000 minio minio123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81f3a7a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32;1mBucket created successfully `minio/models`.\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!./mc mb minio/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc9016",
   "metadata": {},
   "source": [
    "## Creating models repository\n",
    "\n",
    "While the Minio is available, we can upload the models for serving in the OpenVINO Model Server. In the demos below will be needed 4 models:\n",
    "- [resnet](https://github.com/onnx/models/tree/master/vision/classification/resnet)\n",
    "- [face detection](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/face-detection-retail-0004/description/face-detection-retail-0004.md)\n",
    "- [age-gender recognition](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/age-gender-recognition-retail-0013/description/age-gender-recognition-retail-0013.md)\n",
    "- [emotion recognition](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/emotions-recognition-retail-0003/description/emotions-recognition-retail-0003.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00ddc393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 30901  100 30901    0     0  48662      0 --:--:-- --:--:-- --:--:-- 48586\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 8351k  100 8351k    0     0  8539k      0 --:--:-- --:--:-- --:--:-- 8530k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  101k  100  101k    0     0   188k      0 --:--:-- --:--:-- --:--:--  188k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2297k  100 2297k    0     0  2429k      0 --:--:-- --:--:-- --:--:-- 2426k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 39391  100 39391    0     0   282k      0 --:--:-- --:--:-- --:--:--  282k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 9697k  100 9697k    0     0  9976k      0 --:--:-- --:--:-- --:--:-- 9966k\n"
     ]
    }
   ],
   "source": [
    "!curl --create-dirs https://storage.openvinotoolkit.org/repositories/open_model_zoo/2021.3/models_bin/2/age-gender-recognition-retail-0013/FP32/age-gender-recognition-retail-0013.xml -o age-gender/1/age-gender-recognition-retail-0013.xml \n",
    "!curl --create-dirs https://storage.openvinotoolkit.org/repositories/open_model_zoo/2021.3/models_bin/2/age-gender-recognition-retail-0013/FP32/age-gender-recognition-retail-0013.bin -o age-gender/1/age-gender-recognition-retail-0013.bin\n",
    "!curl --create-dirs https://storage.openvinotoolkit.org/repositories/open_model_zoo/2021.3/models_bin/2/face-detection-retail-0004/FP32/face-detection-retail-0004.xml -o face-detection/1/face-detection-retail-0004.xml\n",
    "!curl --create-dirs https://storage.openvinotoolkit.org/repositories/open_model_zoo/2021.3/models_bin/2/face-detection-retail-0004/FP32/face-detection-retail-0004.bin -o face-detection/1/face-detection-retail-0004.bin\n",
    "!curl --create-dirs https://storage.openvinotoolkit.org/repositories/open_model_zoo/2021.3/models_bin/2/emotions-recognition-retail-0003/FP32/emotions-recognition-retail-0003.xml -o emotions/1/emotions-recognition-retail-0003.xml\n",
    "!curl --create-dirs https://storage.openvinotoolkit.org/repositories/open_model_zoo/2021.3/models_bin/2/emotions-recognition-retail-0003/FP32/emotions-recognition-retail-0003.bin -o emotions/1/emotions-recognition-retail-0003.xml\n",
    "!curl -L --create-dir https://github.com/onnx/models/raw/master/vision/classification/resnet/model/resnet50-caffe2-v1-9.onnx -o resnet/1/resnet50-caffe2-v1-9.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "890a69d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...-0003.xml:  18.98 MiB / 18.98 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 223.99 MiB/s 0s\u001b[0m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "!./mc cp --recursive age-gender minio/models/\n",
    "!./mc cp --recursive face-detection minio/models/\n",
    "!./mc cp --recursive emotion minio/models/\n",
    "!./mc cp --recursive resnet minio/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e23dd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32m[2021-04-21 15:58:35 UTC]\u001b[0m\u001b[33m 8.2MiB\u001b[0m\u001b[1m age-gender/1/age-gender-recognition-retail-0013.bin\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2021-04-21 15:58:35 UTC]\u001b[0m\u001b[33m  30KiB\u001b[0m\u001b[1m age-gender/1/age-gender-recognition-retail-0013.xml\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2021-04-21 15:58:36 UTC]\u001b[0m\u001b[33m 9.5MiB\u001b[0m\u001b[1m emotions/1/emotions-recognition-retail-0003.xml\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2021-04-21 15:58:36 UTC]\u001b[0m\u001b[33m 2.2MiB\u001b[0m\u001b[1m face-detection/1/face-detection-retail-0004.bin\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2021-04-21 15:58:36 UTC]\u001b[0m\u001b[33m 102KiB\u001b[0m\u001b[1m face-detection/1/face-detection-retail-0004.xml\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2021-04-21 20:37:26 UTC]\u001b[0m\u001b[33m 101KiB\u001b[0m\u001b[1m resnet/1/resnet50-caffe2-v1-9.onnx\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!./mc ls -r minio/models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceebe29",
   "metadata": {},
   "source": [
    "With the model repository created, we can move on the deploying OpenVINO Model Server in the cluster.\n",
    "\n",
    "## OpenVINO Model Server deployment with a single model\n",
    "\n",
    "The first scenario will be with a serving a single model. In the demo, there will be performed image classification using ResNet50 model in ONNX format.\n",
    "\n",
    "While the operator in place, starting the inference service is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "79049f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: intel.com/v1alpha1\n",
      "kind: Ovms\n",
      "metadata:\n",
      "  name: ovms-resnet\n",
      "spec:\n",
      "  aws_access_key_id: \"minio\"\n",
      "  aws_region: \"us-east-1\"\n",
      "  aws_secret_access_key: \"minio123\"\n",
      "  grpc_port: 8080\n",
      "  image_name: registry.connect.redhat.com/intel/openvino-model-server:latest\n",
      "  log_level: INFO\n",
      "  model_name: \"resnet\"\n",
      "  model_path: \"s3://minio-service:9000/models/resnet\"\n",
      "  plugin_config: '{\\\"CPU_THROUGHPUT_STREAMS\\\":\\\"1\\\"}'\n",
      "  replicas: 1\n",
      "  resources:\n",
      "    limits:\n",
      "      cpu: 4\n",
      "      memory: 500Mi\n",
      "  rest_port: 8081\n",
      "  service_type: ClusterIP\n"
     ]
    }
   ],
   "source": [
    "!curl -s https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/ovms-demo/notebooks/202-model-server/ovms-resnet.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c3b5bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ovms.intel.com/ovms-resnet configured\n"
     ]
    }
   ],
   "source": [
    "!oc apply -f https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/ovms-demo/notebooks/202-model-server/ovms-resnet.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f446150f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                           READY     STATUS    RESTARTS   AGE\n",
      "minio-5c57f888dd-9q7k8         1/1       Running   0          7h20m\n",
      "ovms-resnet-7cdb696f7b-jb6lf   1/1       Running   0          56s\n",
      "NAME            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE\n",
      "minio-service   ClusterIP   172.30.116.144   <none>        9000/TCP            7h20m\n",
      "ovms-resnet     ClusterIP   172.30.95.150    <none>        8080/TCP,8081/TCP   33m\n"
     ]
    }
   ],
   "source": [
    "!oc get pod\n",
    "!oc get service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5291e1b",
   "metadata": {},
   "source": [
    "With those steps, OpenVINO Model Server is running and is ready to accept inference requests. The status of models can be queries with a simple REST API calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d7daf452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"model_version_status\": [\n",
      "  {\n",
      "   \"version\": \"1\",\n",
      "   \"state\": \"AVAILABLE\",\n",
      "   \"status\": {\n",
      "    \"error_code\": \"OK\",\n",
      "    \"error_message\": \"OK\"\n",
      "   }\n",
      "  }\n",
      " ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl http://ovms-resnet.ovms.svc:8081/v1/models/resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3d8b281f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"modelSpec\": {\n",
      "  \"name\": \"resnet\",\n",
      "  \"signatureName\": \"\",\n",
      "  \"version\": \"1\"\n",
      " },\n",
      " \"metadata\": {\n",
      "  \"signature_def\": {\n",
      "   \"@type\": \"type.googleapis.com/tensorflow.serving.SignatureDefMap\",\n",
      "   \"signatureDef\": {\n",
      "    \"serving_default\": {\n",
      "     \"inputs\": {\n",
      "      \"gpu_0/data_0\": {\n",
      "       \"dtype\": \"DT_FLOAT\",\n",
      "       \"tensorShape\": {\n",
      "        \"dim\": [\n",
      "         {\n",
      "          \"size\": \"1\",\n",
      "          \"name\": \"\"\n",
      "         },\n",
      "         {\n",
      "          \"size\": \"3\",\n",
      "          \"name\": \"\"\n",
      "         },\n",
      "         {\n",
      "          \"size\": \"224\",\n",
      "          \"name\": \"\"\n",
      "         },\n",
      "         {\n",
      "          \"size\": \"224\",\n",
      "          \"name\": \"\"\n",
      "         }\n",
      "        ],\n",
      "        \"unknownRank\": false\n",
      "       },\n",
      "       \"name\": \"gpu_0/data_0\"\n",
      "      }\n",
      "     },\n",
      "     \"outputs\": {\n",
      "      \"gpu_0/softmax_1\": {\n",
      "       \"dtype\": \"DT_FLOAT\",\n",
      "       \"tensorShape\": {\n",
      "        \"dim\": [\n",
      "         {\n",
      "          \"size\": \"1\",\n",
      "          \"name\": \"\"\n",
      "         },\n",
      "         {\n",
      "          \"size\": \"1000\",\n",
      "          \"name\": \"\"\n",
      "         }\n",
      "        ],\n",
      "        \"unknownRank\": false\n",
      "       },\n",
      "       \"name\": \"gpu_0/softmax_1\"\n",
      "      }\n",
      "     },\n",
      "     \"methodName\": \"\"\n",
      "    }\n",
      "   }\n",
      "  }\n",
      " }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl http://ovms-resnet.ovms.svc:8081/v1/models/resnet/metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad63e64",
   "metadata": {},
   "source": [
    "## Running predition requests\n",
    "\n",
    "Lets copy an axilary file with ImageNet class names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e7547a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/openvinotoolkit/model_server/main/example_client/classes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a6c129cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grpc\n",
    "import numpy as np\n",
    "import classes\n",
    "from tensorflow import make_tensor_proto, make_ndarray, make_tensor_proto\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "import cv2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39864c09",
   "metadata": {},
   "source": [
    "Next we create functions formating the array out of input image. The array will be transofrmed to required format and data range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cba262b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/openvinotoolkit/model_server/raw/main/example_client/images/bee.jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cc460ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img_data):\n",
    "    mean_vec = np.array([0.485, 0.456, 0.406])\n",
    "    stddev_vec = np.array([0.229, 0.224, 0.225])\n",
    "    norm_img_data = np.zeros(img_data.shape).astype('float32')\n",
    "    for i in range(img_data.shape[0]):\n",
    "         # for each pixel in each channel, divide the value by 255 to get value between [0, 1] and then normalize\n",
    "        norm_img_data[i,:,:] = (img_data[i,:,:]/255 - mean_vec[i]) / stddev_vec[i]\n",
    "    return norm_img_data\n",
    "\n",
    "def getJpeg(path, size):\n",
    "    with open(path, mode='rb') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    img = np.frombuffer(content, dtype=np.uint8)\n",
    "    img = cv2.imdecode(img, cv2.IMREAD_COLOR)  # BGR format\n",
    "    # format of data is HWC\n",
    "    # add image preprocessing if needed by the model\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img.astype('float32')\n",
    "    #convert to RGB instead of BGR if required by model\n",
    "    img = img[:, :, [2, 1, 0]]\n",
    "    img = img.transpose(2,0,1)\n",
    "    # normalize to adjust to model training dataset\n",
    "    img = preprocess(img)\n",
    "    img = img.reshape(1,3,size,size)\n",
    "    print(path, img.shape, \"; data range:\",np.amin(img),\":\",np.amax(img))\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a31678",
   "metadata": {},
   "source": [
    "Let's try to classify this image:\n",
    "\n",
    "![image](https://github.com/openvinotoolkit/model_server/raw/main/example_client/images/bee.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5b395d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bee.jpeg (1, 3, 224, 224) ; data range: -2.0665298 : 2.3785625\n",
      "Class is with highest score: 309\n",
      "Detected class name: bee\n"
     ]
    }
   ],
   "source": [
    "img1 = getJpeg('bee.jpeg', 224)\n",
    "\n",
    "channel = grpc.insecure_channel(\"ovms-resnet.ovms.svc:8080\")\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "\n",
    "request = predict_pb2.PredictRequest()\n",
    "request.model_spec.name = \"resnet\"\n",
    "request.inputs[\"gpu_0/data_0\"].CopyFrom(make_tensor_proto(img1, shape=(img1.shape)))\n",
    "result = stub.Predict(request, 10.0) # result includes a dictionary with all model outputs\n",
    "\n",
    "output = make_ndarray(result.outputs[\"gpu_0/softmax_1\"])\n",
    "ma = np.argmax(output)\n",
    "print(\"Class is with highest score: {}\".format(ma))\n",
    "print(\"Detected class name: {}\".format(classes.imagenet_classes[ma]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53649dea",
   "metadata": {},
   "source": [
    "That concludes the demonstration of a simple inference request. Now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
